<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=theme-color content="dark"><title>Using DuckDB to analyze NGINX logs | Aiman Ismail</title>
<meta property="og:site_name" content="Aiman Ismail"><meta property="og:title" content="Using DuckDB to analyze NGINX logs | Aiman Ismail"><meta itemprop=name content="Using DuckDB to analyze NGINX logs | Aiman Ismail"><meta name=twitter:title content="Using DuckDB to analyze NGINX logs | Aiman Ismail"><meta name=application-name content="Using DuckDB to analyze NGINX logs | Aiman Ismail"><meta name=twitter:card content="summary"><meta name=description content="I'm learning stuff."><meta name=twitter:description content="I'm learning stuff."><meta itemprop=description content="I'm learning stuff."><meta property="og:description" content="I'm learning stuff."><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=stylesheet href=/sass/main.min.ab99ff095f832511e24ffb2fba2b51ad473b2f7e9301d674eba2c6c3a6e8bd81.css><script src=https://beamanalytics.b-cdn.net/beam.min.js data-token=e393181a-2c64-49b0-8360-7566dfad6e5c async></script></head><script>(function(){const e="ThemeColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="ThemeColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.userColorScheme="dark":document.documentElement.dataset.userColorScheme="light"})()</script><body class=dark><nav class=navbar><div class=container><div class=flex><div><a class=brand href=/>Aiman Ismail</a></div><div class=flex><a href=/articles/>Articles</a>
<button id=dark-mode-button><svg class="light" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" width="1em" height="1em" style="-ms-transform:rotate(360deg);-webkit-transform:rotate(360deg);transform:rotate(360deg)" viewBox="0 0 36 36"><path fill="#ffd983" d="M30.312.776C32 19 20 32 .776 30.312c8.199 7.717 21.091 7.588 29.107-.429C37.9 21.867 38.03 8.975 30.312.776z"/><path d="M30.705 15.915a1.163 1.163.0 101.643 1.641 1.163 1.163.0 00-1.643-1.641zm-16.022 14.38a1.74 1.74.0 000 2.465 1.742 1.742.0 100-2.465zm13.968-2.147a2.904 2.904.0 01-4.108.0 2.902 2.902.0 010-4.107 2.902 2.902.0 014.108.0 2.902 2.902.0 010 4.107z" fill="#ffcc4d"/><rect x="0" y="0" width="36" height="36" fill="rgba(0, 0, 0, 0)"/></svg><svg class="dark" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" width="1em" height="1em" style="-ms-transform:rotate(360deg);-webkit-transform:rotate(360deg);transform:rotate(360deg)" viewBox="0 0 36 36"><path fill="#ffd983" d="M16 2s0-2 2-2 2 2 2 2v2s0 2-2 2-2-2-2-2V2zm18 14s2 0 2 2-2 2-2 2h-2s-2 0-2-2 2-2 2-2h2zM4 16s2 0 2 2-2 2-2 2H2s-2 0-2-2 2-2 2-2h2zm5.121-8.707s1.414 1.414.0 2.828-2.828.0-2.828.0L4.878 8.708s-1.414-1.414.0-2.829c1.415-1.414 2.829.0 2.829.0l1.414 1.414zm21 21s1.414 1.414.0 2.828-2.828.0-2.828.0l-1.414-1.414s-1.414-1.414.0-2.828 2.828.0 2.828.0l1.414 1.414zm-.413-18.172s-1.414 1.414-2.828.0.0-2.828.0-2.828l1.414-1.414s1.414-1.414 2.828.0.0 2.828.0 2.828l-1.414 1.414zm-21 21s-1.414 1.414-2.828.0.0-2.828.0-2.828l1.414-1.414s1.414-1.414 2.828.0.0 2.828.0 2.828l-1.414 1.414zM16 32s0-2 2-2 2 2 2 2v2s0 2-2 2-2-2-2-2v-2z"/><circle fill="#ffd983" cx="18" cy="18" r="10"/><rect x="0" y="0" width="36" height="36" fill="rgba(0, 0, 0, 0)"/></svg></button></div></div></div></nav><main><div class=container><article><header class=article-header><div class=thumb><div><h1>Using DuckDB to analyze NGINX logs</h1><div class=post-meta><div>By Aiman Ismail | <time>October 27, 2024</time>
| 6 minutes</div><div class=tags><a href=/tags/security/>Security</a>
<a href=/tags/duckdb/>Duckdb</a>
<a href=/tags/analytics/>Analytics</a>
<a href=/tags/ingress-nginx/>Ingress-Nginx</a>
<a href=/tags/k8s/>K8s</a></div></div></div></div></header></article><div class=article-post><p>As part of my recent <a href=https://pokgak.xyz/articles/we-got-ddosed/>DDoS mitigation effort</a>, I had to go through millions of nginx logs to identify patterns that I can use to further improve our custom WAF rules on Cloudflare. This article shows what I did to be able to run some analysis on the logs using DuckDB.</p><h2 id=making-the-hard-things-easy><a href=#making-the-hard-things-easy class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>
</a>Making the hard things easy</h2><h3 id=changing-the-log-format><a href=#changing-the-log-format class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>
</a>Changing the log format</h3><blockquote><p>&ldquo;To solve a problem that is difficult, you must first make it easy.&rdquo;</p></blockquote><p>The default nginx access logs format looks something like this:</p><pre tabindex=0><code>&#39;$remote_addr - $remote_user [$time_local] &#39;&#39;&#34;$request&#34; $status $body_bytes_sent &#39; &#39;&#34;$http_referer&#34; &#34;$http_user_agent&#34;&#39;
</code></pre><p>Parsing it is definitely possible using regex as shown by <a href=https://www.alibabacloud.com/help/en/sls/user-guide/parse-nginx-logs>this article</a> but why bother when you have the option to change the format and make it easier to parse using DuckDB. To do so we will be configuring ingress-nginx controller in our cluster to log in JSON format. You can set the custom log format using the <code>log-format-upstream</code> config and set <code>log-format-escape-json</code> to make sure that the variables are escaped properly for use in as JSON variables.</p><p>This is the log format that I&rsquo;m currently using:</p><pre tabindex=0><code>&#39;{&#34;timestamp&#34;: &#34;$time_iso8601&#34;, &#34;requestID&#34;: &#34;$req_id&#34;, &#34;proxyUpstreamName&#34;: &#34;$proxy_upstream_name&#34;, &#34;proxyAlternativeUpstreamName&#34;: &#34;$proxy_alternative_upstream_name&#34;,&#34;upstreamStatus&#34;: &#34;$upstream_status&#34;, &#34;upstreamAddr&#34;: &#34;$upstream_addr&#34;,&#34;method&#34;: &#34;$request_method&#34;, &#34;host&#34;: &#34;$host&#34;, &#34;uri&#34;: &#34;$uri&#34;, &#34;uriNormalized&#34;: &#34;$uri_normalized&#34;, &#34;uriWithParams&#34;: &#34;$request_uri&#34;, &#34;status&#34;: $status,&#34;requestSize&#34;: &#34;$request_length&#34;, &#34;responseSize&#34;: &#34;$upstream_response_length&#34;, &#34;userAgent&#34;: &#34;$http_user_agent&#34;, &#34;remoteIp&#34;: &#34;$remote_addr&#34;, &#34;referer&#34;: &#34;$http_referer&#34;, &#34;latency&#34;: &#34;$upstream_response_time s&#34;, &#34;protocol&#34;:&#34;$server_protocol&#34;}&#39;
</code></pre><h3 id=mapping-customer-ids-to-generic-placeholder><a href=#mapping-customer-ids-to-generic-placeholder class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>
</a>Mapping customer IDs to generic placeholder</h3><p>One thing I don&rsquo;t know how to do with DuckDB is normalizing URIs. Given a URI path containing user ID 12345678 like <code>/users/1234567/info</code>. How do I group by path where I ignore the middle section and group it as if all the URIs are like <code>/users/:userId/info</code>. I tried regex and patterns but couldn&rsquo;t get it to work. If you know how to do it please DM me on Twitter, I&rsquo;d really appreciate it.</p><p>I found a way to do it in nginx instead. It works but its definitely not scalable. I use the <code>ngx_http_map_module</code> module to match URIs with certain paths and then convert it to a generic version of that path.</p><pre tabindex=0><code>map $uri $uri_normalized {
    &#34;~^/user/(.*)$&#34; &#34;/user/:ID&#34;;
    default $uri;
}
</code></pre><p>This snippet will do the following: for each of the variable <code>$uri</code>, map it to a new variable <code>$uri_normalized</code>. When <code>$uri</code> value matches the regex <code>^/user/(.*)$</code>, the replace the value with new value <code>/users/ID</code>. If no matching regex found, then use default to the value of <code>$uri</code>.</p><p>With those configured, you can proceed to ship the logs to your logging backend of choice to retrieve later.</p><h2 id=fetching-the-logs-from-loki><a href=#fetching-the-logs-from-loki class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>
</a>Fetching the logs from Loki</h2><p>I&rsquo;m using Loki as my logging backend. Loki provides an API endpoint you can use to fetch the logs and to make things easier they also have an CLI tool called <a href=https://grafana.com/docs/loki/latest/query/logcli/>logcli</a>.</p><p>To fetch all nginx logs from my production cluster, this is the command that I used:</p><pre tabindex=0><code>$ logcli query -oraw --from=&#34;2024-10-24T00:00:00+08:00&#34; --to=&#34;2024-10-24T22:00:00+08:00&#34; --part-path-prefix=&#34;logs&#34; --parallel-max-workers=100 --parallel-duration=15m &#39;{namespace=&#34;ingress-nginx&#34;, cluster=&#34;production&#34;} | json | __error__=``&#39;
</code></pre><ul><li><code>-oraw</code> is to set the output format of the logs. I&rsquo;m using the raw format here so that I can get the same JSON input that I sent to Loki</li><li><code>--from</code> and <code>--to</code> are self-explanatory but I did have some problem specifying the correct format that the tool will accept and the official docs was quite confusing</li><li><code>--part-path-prefix</code> use this prefix to name the files when downloading multiple files in parallel</li><li><code>--parallel-max-workers</code> sets the max parallel workers to be used. Note that the actual workers used depends also on the available tasks based on the parallel duration configured</li><li><code>--parallel-duration</code> is the duration size to use for each file. combined with the <code>--from</code> and <code>--to</code> option, this option determines how many files will be created e.g. for 1 hour duration and you&rsquo;ve specified the <code>--parallel-duration</code> there will be 4 files created, each containing logs from specific 15 minutes section.</li></ul><h2 id=loading-the-logs-into-duckdb><a href=#loading-the-logs-into-duckdb class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>
</a>Loading the logs into DuckDB</h2><p>I&rsquo;m using the CLI version of duckdb but you can also do this using the embedded library in other languages of your choice.</p><p>To read the files we&rsquo;ve pulled from Loki and create a table with it I used this command:</p><pre tabindex=0><code>create table logs as select * from read_json(&#39;logs_*.part&#39;, format=&#39;auto&#39;, columns={timestamp: &#39;TIMESTAMP&#39;, method: &#39;VARCHAR&#39;, host: &#39;VARCHAR&#39;, uri: &#39;VARCHAR&#39;, uriNormalized: &#39;VARCHAR&#39;, status:&#39;INT&#39;, remoteIp: &#39;VARCHAR&#39;, is_authed: &#39;BOOLEAN&#39;, userAgent: &#39;VARCHAR&#39;});
</code></pre><p><code>read_json</code> can automatically create all the columns based on the keys in the JSON files but I want it to treat certain columns as specific data types so that&rsquo;s why I&rsquo;m specifying the columns manually here.</p><p>After loading the columns into the table you can check the number of rows using this commands:</p><pre tabindex=0><code>select count() from logs;
</code></pre><p>In my case, for a day&rsquo;s worth of logs from nginx, I have around 60 million rows. On idle, its using around 8GBs of RAM. If you have longer periods of logs to analyze, then definitely opt for a beefier machine or else DuckDB will crash.</p><h2 id=running-queries><a href=#running-queries class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>
</a>Running queries</h2><p>Its the fun part. Here&rsquo;s some queries that I find useful:</p><h3 id=highest-requests-per-minute-grouped-by-ip><a href=#highest-requests-per-minute-grouped-by-ip class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>
</a>Highest requests per minute grouped by IP</h3><p>I use this information to set the proper value to use in our Cloudflare rate limiting rule. By looking at existing request rate I&rsquo;m reducing the chance of rate limiting our actual customers.</p><pre tabindex=0><code>select
        (hour(timestamp) + 8) % 24 as hour,
        minute(timestamp) as minute,
        remoteIp,
        count() as total
from logs
where remoteIp not in (&#39;X.X.X.X&#39;, &#39;Y.Y.Y.Y&#39;, &#39;Z.Z.Z.Z&#39;) --production NAT gateway IPs
and remoteIp not like &#39;162.158.192.%&#39;   --cloudflare IPs
group by all
order by total desc
limit 5;
</code></pre><h3 id=ip-address-with-the-highest-number-of-request-to-a-particular-host><a href=#ip-address-with-the-highest-number-of-request-to-a-particular-host class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>
</a>IP address with the highest number of request to a particular host</h3><pre tabindex=0><code>select remoteIp, count() as total from logs where host = &#39;subdomain.example.com&#39; group by all order by total desc limit 10;
</code></pre><h3 id=checking-the-paths-an-ip-have-been-sending-requests-to><a href=#checking-the-paths-an-ip-have-been-sending-requests-to class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>
</a>Checking the paths an IP have been sending requests to</h3><p>I&rsquo;m including the result from the query here since it shows that this particular IP most likely are using a scanner to find vulnerable endpoints on our service.</p><pre tabindex=0><code>select uri, count() as total from logs where remoteIp = &#39;152.32.189.70&#39; group by all order by total desc limit 20;
┌─────────────────────────────────────────────────────────────────┬───────┐
│                               uri                               │ total │
│                             varchar                             │ int64 │
├─────────────────────────────────────────────────────────────────┼───────┤
│ /                                                               │    10 │
│ /favicon.ico                                                    │     6 │
│ /api/user/ismustmobile                                          │     6 │
│ /h5/                                                            │     4 │
│ /m/                                                             │     4 │
│ /api                                                            │     4 │
│ /app/                                                           │     3 │
│ /api/config                                                     │     3 │
│ /leftDao.php?callback=jQuery183016740860980352856_1604309800583 │     2 │
│ /public/static/home/js/moblie/login.js                          │     2 │
│ /static/home/css/feiqi-ee5401a8e6.css                           │     2 │
│ /client/static/icon/hangqingicon.png                            │     2 │
│ /admin/webadmin.php?mod=do&amp;act=login                            │     2 │
│ /static/images/auth/background.png                              │     2 │
│ /index/index/home?business_id=1                                 │     2 │
│ /stage-api/common/configKey/all                                 │     2 │
│ /Public/home/common/js/index.js                                 │     2 │
│ /ws/index/getTheLotteryInitList                                 │     2 │
│ /app/static/picture/star.png                                    │     2 │
│ /resource/home/js/common.js                                     │     2 │
├─────────────────────────────────────────────────────────────────┴───────┤
│ 20 rows                                                       2 columns │
└─────────────────────────────────────────────────────────────────────────┘
</code></pre><h2 id=conclusion><a href=#conclusion class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>
</a>Conclusion</h2><p>This has been an adhoc task and when I was told to do some analysis on the logs I immediately think of the tools I&rsquo;m familiar with which is DuckDB to do the analysis. I&rsquo;m aware there are better tools out there and we are currently evaluating using OpenSearch Security Analytics to automatically do this kind of detection in the future. Hopefully, I can talk about it soon. If any of you data analyst/data engineer out there got better ways to do the things I&rsquo;m doing feel free to tweet me @pokgak73 on Twitter.</p></div></div><div class=container><nav class="flex container suggested"><a rel=prev href=/articles/we-got-ddosed/ title="Previous post (older)"><span>Previous</span>
We got DDoSed
</a><a rel=next href=/articles/docker-bake/ title="Next post (newer)"><span>Next</span>
Docker's lesser known command: buildx bake</a></nav></div><div class=container></div></main></main><footer class="footer flex"><section class=container><nav class=footer-links><a href=/index.xml>RSS</a></nav></section><script defer src=/ts/features.706a523ba43e6d0427c7fdf2b9d05dbd0920d3f12942b453690b495cb2522743.js data-enable-footnotes=true></script></footer></body></html>
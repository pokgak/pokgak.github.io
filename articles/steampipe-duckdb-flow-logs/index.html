<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=theme-color content="dark"><title>Using Steampipe + DuckDB for VPC Flow Logs Analysis | Aiman Ismail</title>
<meta property="og:site_name" content="Aiman Ismail"><meta property="og:title" content="Using Steampipe + DuckDB for VPC Flow Logs Analysis | Aiman Ismail"><meta itemprop=name content="Using Steampipe + DuckDB for VPC Flow Logs Analysis | Aiman Ismail"><meta name=twitter:title content="Using Steampipe + DuckDB for VPC Flow Logs Analysis | Aiman Ismail"><meta name=application-name content="Using Steampipe + DuckDB for VPC Flow Logs Analysis | Aiman Ismail"><meta name=twitter:card content="summary"><meta name=description content="I'm learning stuff."><meta name=twitter:description content="I'm learning stuff."><meta itemprop=description content="I'm learning stuff."><meta property="og:description" content="I'm learning stuff."><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=stylesheet href=/sass/main.min.ab99ff095f832511e24ffb2fba2b51ad473b2f7e9301d674eba2c6c3a6e8bd81.css><script src=https://beamanalytics.b-cdn.net/beam.min.js data-token=e393181a-2c64-49b0-8360-7566dfad6e5c async></script></head><script>(function(){const e="ThemeColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="ThemeColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.userColorScheme="dark":document.documentElement.dataset.userColorScheme="light"})()</script><body class=dark><nav class=navbar><div class=container><div class=flex><div><a class=brand href=/>Aiman Ismail</a></div><div class=flex><a href=/articles/>Articles</a>
<button id=dark-mode-button><svg class="light" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" width="1em" height="1em" style="-ms-transform:rotate(360deg);-webkit-transform:rotate(360deg);transform:rotate(360deg)" viewBox="0 0 36 36"><path fill="#ffd983" d="M30.312.776C32 19 20 32 .776 30.312c8.199 7.717 21.091 7.588 29.107-.429C37.9 21.867 38.03 8.975 30.312.776z"/><path d="M30.705 15.915a1.163 1.163.0 101.643 1.641 1.163 1.163.0 00-1.643-1.641zm-16.022 14.38a1.74 1.74.0 000 2.465 1.742 1.742.0 100-2.465zm13.968-2.147a2.904 2.904.0 01-4.108.0 2.902 2.902.0 010-4.107 2.902 2.902.0 014.108.0 2.902 2.902.0 010 4.107z" fill="#ffcc4d"/><rect x="0" y="0" width="36" height="36" fill="rgba(0, 0, 0, 0)"/></svg><svg class="dark" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" width="1em" height="1em" style="-ms-transform:rotate(360deg);-webkit-transform:rotate(360deg);transform:rotate(360deg)" viewBox="0 0 36 36"><path fill="#ffd983" d="M16 2s0-2 2-2 2 2 2 2v2s0 2-2 2-2-2-2-2V2zm18 14s2 0 2 2-2 2-2 2h-2s-2 0-2-2 2-2 2-2h2zM4 16s2 0 2 2-2 2-2 2H2s-2 0-2-2 2-2 2-2h2zm5.121-8.707s1.414 1.414.0 2.828-2.828.0-2.828.0L4.878 8.708s-1.414-1.414.0-2.829c1.415-1.414 2.829.0 2.829.0l1.414 1.414zm21 21s1.414 1.414.0 2.828-2.828.0-2.828.0l-1.414-1.414s-1.414-1.414.0-2.828 2.828.0 2.828.0l1.414 1.414zm-.413-18.172s-1.414 1.414-2.828.0.0-2.828.0-2.828l1.414-1.414s1.414-1.414 2.828.0.0 2.828.0 2.828l-1.414 1.414zm-21 21s-1.414 1.414-2.828.0.0-2.828.0-2.828l1.414-1.414s1.414-1.414 2.828.0.0 2.828.0 2.828l-1.414 1.414zM16 32s0-2 2-2 2 2 2 2v2s0 2-2 2-2-2-2-2v-2z"/><circle fill="#ffd983" cx="18" cy="18" r="10"/><rect x="0" y="0" width="36" height="36" fill="rgba(0, 0, 0, 0)"/></svg></button></div></div></div></nav><main><div class=container><article><header class=article-header><div class=thumb><div><h1>Using Steampipe + DuckDB for VPC Flow Logs Analysis</h1><div class=post-meta><div>By Aiman Ismail | <time>January 26, 2024</time>
| 5 minutes</div><div class=tags><a href=/tags/duckdb/>duckdb</a>
<a href=/tags/steampipe/>steampipe</a>
<a href=/tags/aws/>aws</a>
<a href=/tags/cloud/>cloud</a>
<a href=/tags/tools/>tools</a>
<a href=/tags/data/>data</a>
<a href=/tags/sql/>sql</a></div></div></div></div></header></article><div class=article-post><p>As a so called <a href="https://x.com/tevanraj/status/1747920076203057273?s=20">Tech Janitor</a>, I&rsquo;ve been tasked to clean up one of our AWS accounts at work and that account have a bunch of EC2 instances that no one knows what they all do. So, I&rsquo;ve decided to use one of AWS features, VPC Flow Logs, to first identify which EC2 instances are still being used and which are not.</p><h2 id=setting-up-the-vpc-flow-logs-and-query-using-duckdb><a href=#setting-up-the-vpc-flow-logs-and-query-using-duckdb class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Setting up the VPC Flow Logs and query using DuckDB</h2><p>For our purpose, I&rsquo;ve setup VPC flow logs to send all the traffic data to a S3 bucket that we&rsquo;ll refer to as <code>vpc-flow-logs-bucket</code> in this post. The flow logs are stored in a Parquet format for querying later using DuckDB.</p><p>Once the flow logs file are sent to S3, I&rsquo;ll be able to query them using DuckDB. To do that we will need to install the <code>aws</code> and <code>httpfs</code> extensions.</p><p>From DuckDB shell:</p><pre tabindex=0><code>&gt; INSTALL aws;
&gt; INSTALL httpfs;
</code></pre><p>We also need to load our AWS credentials into DuckDB. Luckily, DuckDB has a built-in command to do that:</p><pre tabindex=0><code>&gt; CALL load_aws_credentials();
┌──────────────────────┬──────────────────────────┬──────────────────────┬───────────────┐
│ loaded_access_key_id │ loaded_secret_access_key │ loaded_session_token │ loaded_region │
│       varchar        │         varchar          │       varchar        │    varchar    │
├──────────────────────┼──────────────────────────┼──────────────────────┼───────────────┤
│ &lt;redacted&gt;           │ &lt;redacted&gt;               │                      │ eu-west-1     │
└──────────────────────┴──────────────────────────┴──────────────────────┴───────────────┘
</code></pre><p>This will look for your AWS credentials based on the standard AWS credentials file location. If you have multiple profiles in your credentials file, you can specify which profile to use by passing the profile name as an argument to the <code>load_aws_credentials</code> function.</p><p>Now it&rsquo;s time to load our VPC flow logs from S3 into a table in DuckDB. You can replace the <code>year/month/day/hour</code> with the actual date and hour of the flow logs that you want to load or use <code>*</code> for any or all of them to load all the flow logs. I&rsquo;ll be loading all the flow log records into a table <code>flow_logs</code> in DuckDB.</p><p>This might take a while since DuckDB will have to download the Parquet files from S3 and load them into memory. It took several minutes to finish loading in my case.</p><pre tabindex=0><code>&gt; CREATE TABLE flow_logs AS SELECT * from read_parquet(&#39;s3://vpc-flow-logs-bucket/AWSLogs/&lt;aws-account-id&gt;/vpcflowlogs/&lt;region&gt;/&lt;year&gt;/&lt;month&gt;/&lt;day&gt;/&lt;hour&gt;/*.parquet&#39;)
</code></pre><p>Now we can see that the flow logs records only contains the network interface ID (ENI) of the EC2 instance but not the EC2 instance ID or name itself. That won&rsquo;t be enough for my use case since I want to identify which traffic is flowing to which EC2 instance. Therefore, we need to correlate the ENI with the EC2 instance ID and here&rsquo;s where Steampipe comes in.</p><h2 id=steampipe-directly-query-your-apis-from-sql><a href=#steampipe-directly-query-your-apis-from-sql class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Steampipe: directly query your APIs from SQL</h2><p>Steampipe is a tool that allows you to query APIs from SQL. It supports a lot of different APIs from AWS, GCP, Azure, Github, etc. You can also write your own plugins to support other APIs. I&rsquo;ll be using it to query my AWS account for the EC2 instance ID and name based on the ENI ID from the VPC flow logs.</p><h2 id=life-before-steampipe><a href=#life-before-steampipe class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Life before Steampipe</h2><p>Usually to do the things I&rsquo;m about to show below, I&rsquo;ll pull the data from AWS using the aws-cli and then massage it using <code>jq/yq/awk/sed</code>, if I&rsquo;m desperate maybe Python. Then I&rsquo;ll use some other tools to visualize it or export to CSV. With Steampipe, pulling the data from AWS is so simple and using SQL to correlate the data with other information source is a breeze.</p><h2 id=steampipe-is-just-postgresql><a href=#steampipe-is-just-postgresql class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Steampipe is just Postgresql</h2><p>Under the hood, Steampipe is running PostgreSQL and it even allows you to run it as a standalone instance running in the background and allows <a href=https://steampipe.io/docs/query/third-party>connecting to it from any third-party tools</a> that can connect to a Postgresql instance. Here&rsquo;s where it gets interesting, DuckDB has the capability to connect to any PostgreSQL database and query it as if all the data inside that database is coming from the DuckDB. This means that we can use Steampipe as a data source for DuckDB and access all of the AWS resources data available in Steampipe.</p><h2 id=setting-up-steampipe-and-duckdb-connection><a href=#setting-up-steampipe-and-duckdb-connection class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Setting up Steampipe and DuckDB connection</h2><p>To run Steampipe as a service mode, you&rsquo;ll need to run the following command to start the PostgreSQL instance and get the credentials for connecting to it:</p><pre tabindex=0><code>$ steampipe service start
Database:

  Host(s):            127.0.0.1, ::1, 2606:4700:110:8818:e17b:f78c:6c52:dccb, 172.16.0.2, 2001:f40:909:8e2:207a:634a:2070:d99d, 2001:f40:909:8e2:1cdb:75da:2a70:4b05, 192.168.100.23, 127.0.2.3, 127.0.2.2
  Port:               9193
  Database:           steampipe
  User:               steampipe
  Password:           ********* [use --show-password to reveal]
  Connection string:  postgres://steampipe@127.0.0.1:9193/steampipe
</code></pre><p>Then inside DuckDB shell, you can connect to the Steampipe PostgreSQL instance using the following command:</p><pre tabindex=0><code>&gt; ATTACH &#39;dbname=steampipe user=steampipe password=23e2_4853_bd96 host=127.0.0.1 port=9193&#39; AS steampipe (TYPE postgres);
&gt; use steampipe.aws;
&gt; SHOW tables;
show tables;
┌─────────────────────────────────────────────┐
│                    name                     │
│                   varchar                   │
├─────────────────────────────────────────────┤
│ aws_accessanalyzer_analyzer                 │
│ aws_account                                 │
│ aws_account_alternate_contact               │
...
</code></pre><p>Now we can see all the tables from the Steampipe Postgresql instance. For my use case I&rsquo;ll be using the <code>aws_ec2_network_interface</code> table which contains both the network interface ID (ENI) and the EC2 instance ID that I can use <code>JOIN</code> together with the VPC flow logs records to map the records to the EC2 instance ID.</p><h2 id=join-ing-it-all-together><a href=#join-ing-it-all-together class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>JOIN-ing it all together</h2><p>Here&rsquo;s an example query that will give me the count of all incoming traffic to the instances grouped by the port number:</p><pre tabindex=0><code>select
    i.title,
    fl.dstport,
    count(fl.dstaddr) traffic
from network_interfaces ni
left join flow_logs fl on fl.interface_id = ni.network_interface_id
left join instances i on i.instance_id = ni.attached_instance_id
where
    fl.dstaddr = i.private_ip_address
group by i.instance_name, fl.dstport
order by traffic desc, dstport asc
</code></pre><p>From this information I&rsquo;ll be able to guess which service is running on those instances and take the next step towards migrating or depecrating the instances.</p><h2 id=conclusion><a href=#conclusion class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>Conclusion</h2><p>It is kinda mindblowing that I can do all this using SQL. Both Steampipe and DuckDB are great products and the flexibility of those tools allows me to
pick and choose the best tool for the job. I first came across Steampipe in one of the podcasts that I listen to but haven&rsquo;t really used it much. Now, after having the opportunity to use it to solve one of my problems, I&rsquo;ll definitely pay more attention to it to make my tech janitor life easier in the future ;)</p></div></div><div class=container><nav class="flex container suggested"><a rel=prev href=/articles/terraform-modules-opinionated/ title="Previous post (older)"><span>Previous</span>
Terraform modules: be opinionated</a></nav></div><div class=container></div></main></main><footer class="footer flex"><section class=container><nav class=footer-links><a href=/index.xml>RSS</a></nav></section><script defer src=/ts/features.706a523ba43e6d0427c7fdf2b9d05dbd0920d3f12942b453690b495cb2522743.js data-enable-footnotes=true></script></footer></body></html>
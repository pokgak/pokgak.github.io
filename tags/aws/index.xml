<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Aws on Aiman Ismail</title><link>https://pokgak.xyz/tags/aws/</link><description>Recent content in Aws on Aiman Ismail</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 24 Jun 2024 13:00:00 +0800</lastBuildDate><atom:link href="https://pokgak.xyz/tags/aws/index.xml" rel="self" type="application/rss+xml"/><item><title>The hidden cost of running your own observability stack</title><link>https://pokgak.xyz/articles/hidden-cost-lgtm/</link><pubDate>Mon, 24 Jun 2024 13:00:00 +0800</pubDate><guid>https://pokgak.xyz/articles/hidden-cost-lgtm/</guid><description>At my latest $job, I was tasked of setting up the LGTM stack (Loki, Grafana, Tempo, Mimir) for observability. Fast forward a few months, I noticed there&amp;rsquo;s a hidden aspect to running the stack that I was not expecting before and that is the network cost, specifically the network transfer cost for cross AZ traffic. At one point we were paying more than $100 per day just for the cross AZ network traffic.</description></item><item><title>Using Steampipe + DuckDB for VPC Flow Logs Analysis</title><link>https://pokgak.xyz/articles/steampipe-duckdb-flow-logs/</link><pubDate>Fri, 26 Jan 2024 20:00:00 +0800</pubDate><guid>https://pokgak.xyz/articles/steampipe-duckdb-flow-logs/</guid><description>As a so called Tech Janitor, I&amp;rsquo;ve been tasked to clean up one of our AWS accounts at work and that account have a bunch of EC2 instances that no one knows what they all do. So, I&amp;rsquo;ve decided to use one of AWS features, VPC Flow Logs, to first identify which EC2 instances are still being used and which are not.
Setting up the VPC Flow Logs and query using DuckDB For our purpose, I&amp;rsquo;ve setup VPC flow logs to send all the traffic data to a S3 bucket that we&amp;rsquo;ll refer to as vpc-flow-logs-bucket in this post.</description></item></channel></rss>